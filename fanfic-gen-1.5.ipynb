{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"bad\" fanfic generator\n",
    "\n",
    "  texts: \n",
    "  \n",
    "  -\"my immortal\" (classic)\n",
    "  -\"trapped in a island with josh hutcherson\" (wattpad)\n",
    "  -\"sold to one direction\" (\"property\" is an official genre on wattpad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz#egg=en_core_web_md==2.3.1 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.18.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.9.6)\n",
      "Requirement already satisfied: setuptools in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (49.2.0.post20200714)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/plummiewummie/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"all-three-abr.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = list(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in list(doc) if w.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14061"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = [w for w in words if w.pos_ == \"NOUN\"]\n",
    "verbs = [w for w in words if w.pos_ == \"VERB\"]\n",
    "adjs = [w for w in words if w.pos_ == \"ADJ\"]\n",
    "advs = [w for w in words if w.pos_ == \"ADV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(doc.sents)\n",
    "words = [w for w in list(doc) if w.is_alpha]\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "entities = list(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [e for e in entities if e.label_ == \"PERSON\"] #there's thousands\n",
    "locations = [e for e in entities if e.label_ == \"LOC\"] # there's nine\n",
    "gpe = [e for e in entities if e.label_ == \"GPE\"] # there's eighty-five and most are names\n",
    "\n",
    "events = [e for e in entities if e.label == \"EVENT\"] #there's zero\n",
    "art = [e for e in entities if e.label == \"WORK_OF_ART\"] #there's zero\n",
    "product = [e for e in entities if e.label == \"PRODUCT\"] #there's zero\n",
    "time = [e for e in entities if e.label == \"TIME\"] #there's zero\n",
    "orgs = [e for e in entities if e.label == \"ORG\"] #do i have to say it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draco\n",
      "katlin\n",
      "Crookshanks\n",
      "Benji\n",
      "Kaitlin\n",
      "kate\n",
      "Draco\n",
      "Harry\n",
      "Thou\n",
      "Loopin\n",
      "Harry\n",
      "Kate\n",
      "josh\n",
      "Kate\n",
      "hepjamas\n",
      "Hogwarts\n",
      "Loopin\n",
      "Kate\n",
      "Hairgrid\n",
      "XXXXXXXXXXXXX666XXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "for item in random.sample(people, 20):\n",
    "    print(item.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_subtree(st):\n",
    "    return ''.join([w.text_with_ws for w in list(st)]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "for word in doc:\n",
    "    if word.dep_ in ('nsubj', 'nsubjpass'):\n",
    "        subjects.append(flatten_subtree(word.subtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_phrases = []\n",
    "for word in doc:\n",
    "    if word.dep_ == 'prep':\n",
    "        prep_phrases.append(flatten_subtree(word.subtree).replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Kate,\n",
       " kate,\n",
       " Vampire,\n",
       " Duff,\n",
       " josh,\n",
       " Kate,\n",
       " Vampire,\n",
       " Niall,\n",
       " Niall,\n",
       " Harry,\n",
       " Draco,\n",
       " Kate]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(people, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "            for word in doc if word.dep_ in ('nsubj', 'nsubjpass')]\n",
    "past_tense_verbs = [word.text for word in words if word.tag_ == 'VBD' and word.lemma_ != 'be']\n",
    "adjectives = [word.text for word in words if word.tag_.startswith('JJ')]\n",
    "nouns = [word.text for word in words if word.tag_.startswith('NN')]\n",
    "prep_phrases = [flatten_subtree(word.subtree).replace(\"\\n\", \" \")\n",
    "                for word in doc if word.dep_ == 'prep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [flatten_subtree(e.subtree).replace(\"\\n\", \" \")\n",
    "          for e in entities if e.label_ =='PERSON']\n",
    "gpe = [flatten_subtree(e.subtree).replace(\"\\n\", \" \")\n",
    "       for e in entities if e.label_ =='GPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hollywood',\n",
       " 'England',\n",
       " 'Hollywood',\n",
       " 'Cheshire where they had auctions of people',\n",
       " 'Hogsmeade']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(people, 5)\n",
    "random.sample(gpe, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Kate Harry this is what I want to do with my life I have always wanted to become an No that and not some freakin i â€œI screamed at my giant Voldemortblack Common lesson..'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": [\n",
    "        \"#introduction#.\",\n",
    "    ],\n",
    "    \"introduction\": [ \n",
    "        \"Hi my name is #name# #name# and I have #adjphrase# (thatâ€™s how I got my name) with #adjphrase# and #adjphrase# that reaches my #adjphrase# and #adjphrase# like #nounphrase# and a lot of people tell me I look like #name# (AN: if u donâ€™t know who they are get da hell out of here!)\",\n",
    "        \"i couldnt believe it #name# had signed me up to the #adjphrase# auction.\",\n",
    "        \"\\\"#name# #name# this is what I want to do with my life I have always wanted to become an #subject# and not some freakin #subject# \\â€œI screamed at my #adjphrase#.\"\n",
    "    ],\n",
    "    \"predicate\": [\n",
    "        \"#verb#\",\n",
    "        \"#verb# #nounphrase#\",\n",
    "        \"#verb# #prepphrase#\"\n",
    "    ],\n",
    "    \"nounphrase\": [\n",
    "        \"#adj# #noun#\",\n",
    "        \"#noun.a#\",\n",
    "        \"#adj.a# #noun#\",\n",
    "        \"the #noun# that #predicate#\"\n",
    "    ],\n",
    "    \"adjphrase\": [\n",
    "        \"#adj# #noun#\"\n",
    "        \"#adj# #adj# #noun#\"\n",
    "        \n",
    "        \n",
    "    ],\n",
    "    \"subject\": subjects,\n",
    "    \"verb\": past_tense_verbs,\n",
    "    \"noun\": nouns,\n",
    "    \"adj\": adjectives,\n",
    "    \"prepphrase\": prep_phrases,\n",
    "    \"name\": people\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my Cheshire said sweetheart you're getting screamed to mehe had the comfy island my thou! hi i'm you\n",
      "looked to the freezer. when did an other Calender. whenever i go In a soft voice, i put a dumbeldor.\n",
      "hi i'm I did in the house. whenever i go Of the concert I put on my black lace-up boots with high\n",
      "heels, i took at me. hi i'm someone saw a part. hi i'm i pulled in a kind of messy bun. whenever i\n",
      "go In fairyland, i did to your rooms. hi i'm we who were both looking very angry loved.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "output = \" \".join([grammar.flatten(\"#origin#\") for i in range(10)])\n",
    "print(fill(output, 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
